146. LRU Cache
Design a data structure that follows the constraints of a Least Recently Used (LRU) cache.

Implement the LRUCache class:

LRUCache(int capacity) Initialize the LRU cache with positive size capacity.
int get(int key) Return the value of the key if the key exists, otherwise return -1.
void put(int key, int value) Update the value of the key if the key exists. Otherwise, add the key-value pair to the cache. If the number of keys exceeds the capacity from this operation, evict the least recently used key.

Follow up:
Could you do get and put in O(1) time complexity?

# Analysis
O(1) complexity: hash table! Key -> Node*(storing key, value)

Evit "the least recently used key": DoubleLinked List, with head and tail
put: add to head, O(1); if necessary, remove tail
get: move to head (remove + add to head)

# Reflection
两个可以学习和思考的地方：
1) 用hash table储存 key -> node*, 每个node储存key和value，这有点“双向映射”的感觉
2) 双向链表。其实这道题是双向链表衍生出来的操作，双向链表是一个有比较大改造空间和应用能力的基础数据结构，要掌握快速搭建的能力。

```c++
struct DLinkedNode{
    int key, value;
    DLinkedNode* prev;
    DLinkedNode* next;
    DLinkedNode(): key(0), value(0), prev(nullptr), next(nullptr) {}
    DLinkedNode(int _key, int _val): key(_key), value(_val), prev(nullptr), next(nullptr) {}
};

class LRUCache {
private:
    unordered_map<int, DLinkedNode*> cache; //key -> node{key, value} map
    DLinkedNode* head;
    DlinkedNode* tail;
    int size;
    int capacity;
public:
    LRUCache(int _capacity): capacity(_capacity), size(0) {
        head = new DLinkedNode;
        tail = new DLinkedNode;
        head -> next = tail;
        tail -> prev = head;
    }
    
    int get(int key) {
        if (cache.find(key) == cache.end()) return -1;
        DLinkedNode* node = cache[key];
        moveToHead(node);
        return node -> value;
    }
    
    void put(int key, int value) {
        if (cache.find(key) != cache.end()) {
            auto node = cache[key];
            node -> value = value;
            moveToHead(node);
        }
        else{
            auto node = new DLinkedNode(key, value);
            cache[key] = node;
            addToHead(node);
            size++;
            if (size > capacity) {
                auto remove = removeTail();
                cache.erase(remove -> key);
                delete remove;
                size--;
            }
        }
    }

    void addToHead(DLinkedNode* node){
        node -> prev = head;
        node -> next = head -> next;

        head -> next -> prev = node;
        head -> next = node;
    }

    void removeNode(DLinkedNode* node){
        node -> prev -> next = node -> next;
        node -> next -> prev = node -> prev;
    }

    void moveToHead(DLinkedNode* node){
        removeNode(node);
        addToHead(node);
    }

    DLinkedNode* removeTail(){
        DLinkedNode* node = tail -> prev;
        removeNode(node);
        return node;
    }
};

/**
 * Your LRUCache object will be instantiated and called as such:
 * LRUCache* obj = new LRUCache(capacity);
 * int param_1 = obj->get(key);
 * obj->put(key,value);
 */
```